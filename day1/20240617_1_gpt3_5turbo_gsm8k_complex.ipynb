{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JfdeleMSPoT",
        "outputId": "f7f6a55e-c793-400e-9fbd-93a3465d6cc3"
      },
      "id": "9JfdeleMSPoT",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9T_JMt1SSZx",
        "outputId": "04751e1b-aa68-4158-a834-57c0f4bd6bb4"
      },
      "id": "A9T_JMt1SSZx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rc2eDs_SVOW",
        "outputId": "2cfd2f22-023f-4ca5-fafc-f8d921d57fe1"
      },
      "id": "-Rc2eDs_SVOW",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7CC6fF8SVRa",
        "outputId": "cb54f8c7-63b5-4431-9deb-500a9d6b41a8"
      },
      "id": "Y7CC6fF8SVRa",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llmlingua"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1lC70OwjSf1",
        "outputId": "cc5993b8-ef76-4e99-dc5f-3fff784f46b9"
      },
      "id": "E1lC70OwjSf1",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llmlingua\n",
            "  Downloading llmlingua-0.2.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: transformers>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from llmlingua) (4.41.2)\n",
            "Collecting accelerate (from llmlingua)\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llmlingua) (2.3.0+cu121)\n",
            "Collecting tiktoken (from llmlingua)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llmlingua) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llmlingua) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (0.23.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.0->llmlingua) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->llmlingua) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->llmlingua)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->llmlingua)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->llmlingua)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->llmlingua)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->llmlingua)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->llmlingua)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->llmlingua)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->llmlingua)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->llmlingua)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->llmlingua)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->llmlingua)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->llmlingua) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->llmlingua)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->llmlingua) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llmlingua) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.0->llmlingua) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.0->llmlingua) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.0->llmlingua) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.0->llmlingua) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->llmlingua) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->llmlingua) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate, llmlingua\n",
            "Successfully installed accelerate-0.31.0 llmlingua-0.2.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awW2TPBySYd-",
        "outputId": "901d7bdd-464d-404b-dd19-7b2f89d0eed8"
      },
      "id": "awW2TPBySYd-",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ./drive/MyDrive/Colab\\ Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMkQjaKZSYgN",
        "outputId": "34237156-3e2b-4e67-fefc-a1bc7e971679"
      },
      "id": "MMkQjaKZSYgN",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_gpt3.5turbo_gsm8k_complex.ipynb\tprompt_hardest.txt  validation_index.npy\n",
            "gpt3.5turbo_gsm8k_complex_202406.ipynb\tUntitled\n",
            "prompt_engineering.ipynb\t\tUntitled0.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q2AnyucSnfW",
        "outputId": "2c84f7f2-0201-461d-8b89-cb8345c3adda"
      },
      "id": "8Q2AnyucSnfW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c3dffb-98fa-4d14-98ef-80c38d290e1b",
      "metadata": {
        "id": "c4c3dffb-98fa-4d14-98ef-80c38d290e1b"
      },
      "source": [
        "# GPT-3.5-Turbo on GSM8K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2f7c15ca-974a-49aa-8212-d9b6730df39a",
      "metadata": {
        "tags": [],
        "id": "2f7c15ca-974a-49aa-8212-d9b6730df39a"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import re\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b63ddea4-8a1a-4629-9aa6-efdd47bf5e4a",
      "metadata": {
        "tags": [],
        "id": "b63ddea4-8a1a-4629-9aa6-efdd47bf5e4a"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"--\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6032026c-70fc-4ba8-b353-fd3ecf78eb00",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279,
          "referenced_widgets": [
            "97cc178f7ca44b2195796bc379a08033",
            "68e4ce4642694f8c85a958a5ae89ad34",
            "8b9e51916f7048ed950b7dc4c37b5115",
            "2f468f8cd0fe46088cc802873af766ac",
            "66c27484052f4e85887da3fbb5062774",
            "e7333f38ee544fbaa861d906a4b4c5d2",
            "86be23882fcf4fa491ac8f83fc48f304",
            "83bb9fea84d249f39aae95d81ec212fd",
            "7c353342ed424a19bcc008d52d55c349",
            "cd6888e5381b47989992048f63ce0dec",
            "84574b7e42f6456fa215d07712a26776",
            "9ee56da57a9f4956aa31c11c385b98d9",
            "82bca68527274246a2459033e4ba3312",
            "e5141d90c54740eca2ca3e30952ab757",
            "f5ae5f4701e94b5d9ba1c8ed18b56b75",
            "25c6b14e24c54cadad2f5dbc559c1b64",
            "2847074f8b0d443482592ac26653f15f",
            "5704a94b68c84cb4a34ec62f6ba42def",
            "18434b8788c04a33b2814bd5310d1e70",
            "c1ce85068de64d018982e1d43490160c",
            "331e35f0c96e4fa3af53db1fd4a49dcf",
            "9a3e7cb1b93343ab97fcbc167ace157d",
            "a45d4538b60041b88103878dae8b70e7",
            "a123ef0a6ea84ac5975c133b8ae42377",
            "63f66c4d589b44db8251eb6d0c6b1e5c",
            "044893f98f274b3ea56c619a6f28c10d",
            "00dc570a45e142fcadee3c428ee85026",
            "7f8df9d64b53477e90f52e024b3f72e1",
            "5626d4f305b443d4973d846e418c5fc3",
            "e713b1d26d494d2698d26a81aa2eb7e5",
            "2a542f3b083c479f8190e14bf0213a02",
            "df0f70d02eac4afca8ce176c8b289f38",
            "6c5b106324d541d2abbe5ea7b6075799",
            "22cce448cfdc4d7bb14be3e354475f37",
            "be5af9a8cd094004baf7eea377026b2e",
            "ea3109c1c4e644cfa5e8c37e37079ee1",
            "eaa79aa6911840948c3139e52ccbf726",
            "1ad278354cbb469e9854325d6474c18d",
            "198d121c4619427bb6a88a2417e7facf",
            "f2047c61e68e4e0d83130c85132199c8",
            "7ff3b6c2f5134b97b2e8fb09880d8dd7",
            "854add91e47040e68e795693d276b3cf",
            "2af15ebcd1c84f058d15ece69058286b",
            "2c2d0e270e544412a9081f94f2e39dd5",
            "f68708518c604d0c9e43f81bd5dd1541",
            "7e1c5dc51e3f4fd1a61e474513b6eade",
            "b20c9f280562496f8340db541742ea5f",
            "3087b995afaf479895acc1894aee6c96",
            "4087824cb5594a8b840946ffab72a7d4",
            "24d11d44196342d1bd9f9a0735b20c77",
            "6b13863bb3d643fc91172fc263881c35",
            "c7deac8a75f44fb5991d985d8d281d2c",
            "5a23f6dc085740c2bd3b9268857a6efe",
            "e3d1126c608342e69b440a3975dfb616",
            "2cfa4e684ae34a90b9d4316ece13a5eb"
          ]
        },
        "id": "6032026c-70fc-4ba8-b353-fd3ecf78eb00",
        "outputId": "062690d0-5a28-498b-fd36-d9f304035720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97cc178f7ca44b2195796bc379a08033"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee56da57a9f4956aa31c11c385b98d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a45d4538b60041b88103878dae8b70e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22cce448cfdc4d7bb14be3e354475f37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f68708518c604d0c9e43f81bd5dd1541"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "gsm8k = load_dataset('gsm8k', 'main')\n",
        "validation_index = np.load('./drive/MyDrive/Colab Notebooks/validation_index.npy')\n",
        "validation_data = gsm8k['train'].select(validation_index)\n",
        "gsm8k_test = gsm8k['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "99da2222-207e-4d78-91a6-527af94c9afd",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "99da2222-207e-4d78-91a6-527af94c9afd",
        "outputId": "86cb02ea-3dcb-462a-bfe4-83555ef2d2a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "gsm8k['train'][0]['question']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0aebf3f1-ff3a-458d-bdd4-42357aafaf20",
      "metadata": {
        "tags": [],
        "id": "0aebf3f1-ff3a-458d-bdd4-42357aafaf20"
      },
      "outputs": [],
      "source": [
        "gsm8k_test = gsm8k['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ca22a6a6-73b4-49dd-bf78-1e7b8d93c58f",
      "metadata": {
        "tags": [],
        "id": "ca22a6a6-73b4-49dd-bf78-1e7b8d93c58f"
      },
      "outputs": [],
      "source": [
        "prompt_complex = open('./drive/MyDrive/Colab Notebooks/prompt_hardest.txt').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "326b98c1-5b9b-41c2-a15b-f676a6814a7a",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "326b98c1-5b9b-41c2-a15b-f676a6814a7a",
        "outputId": "934e5308-d5fa-4325-b5dc-f65df20b4df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Angelo and Melanie want to plan how many hours over the next week they should study together for their test next week. They have 2 chapters of their textbook to study and 4 worksheets to memorize. They figure out that they should dedicate 3 hours to each chapter of their textbook and 1.5 hours for each worksheet. If they plan to study no more than 4 hours each day, how many days should they plan to study total over the next week if they take a 10-minute break every hour, include 3 10-minute snack breaks each day, and 30 minutes for lunch each day?\n",
            "Let's think step by step\n",
            "Angelo and Melanie think they should dedicate 3 hours to each of the 2 chapters, 3 hours x 2 chapters = 6 hours total.\n",
            "For the worksheets they plan to dedicate 1.5 hours for each worksheet, 1.5 hours x 4 worksheets = 6 hours total.\n",
            "Angelo and Melanie need to start with planning 12 hours to study, at 4 hours a day, 12 / 4 = 3 days.\n",
            "However, they need to include time for breaks and lunch. Every hour they want to include a 10-minute break, so 12 total hours x 10 minutes = 120 extra minutes for breaks.\n",
            "They also want to include 3 10-minute snack breaks, 3 x 10 minutes = 30 minutes.\n",
            "And they want to include 30 minutes for lunch each day, so 120 minutes for breaks + 30 minutes for snack breaks + 30 minutes for lunch = 180 minutes, or 180 / 60 minutes per hour = 3 extra hours.\n",
            "So Angelo and Melanie want to plan 12 hours to study + 3 hours of breaks = 15 hours total.\n",
            "They want to study no more than 4 hours each day, 15 hours / 4 hours each day = 3.75\n",
            "They will need to plan to study 4 days to allow for all the time they need.\n",
            "The answer is 4\n",
            "\n",
            "Question: Mark's basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws.  Their opponents score double the 2 pointers but half the 3 pointers and free throws.  What's the total number of points scored by both teams added together?\n",
            "Let's think step by step\n",
            "Mark's team scores 25 2 pointers, meaning they scored 25*2= 50 points in 2 pointers.\n",
            "His team also scores 6 3 pointers, meaning they scored 8*3= 24 points in 3 pointers\n",
            "They scored 10 free throws, and free throws count as one point so they scored 10*1=10 points in free throws.\n",
            "All together his team scored 50+24+10= 84 points\n",
            "Mark's opponents scored double his team's number of 2 pointers, meaning they scored 50*2=100 points in 2 pointers.\n",
            "His opponents scored half his team's number of 3 pointers, meaning they scored 24/2= 12 points in 3 pointers.\n",
            "They also scored half Mark's team's points in free throws, meaning they scored 10/2=5 points in free throws.\n",
            "All together Mark's opponents scored 100+12+5=117 points\n",
            "The total score for the game is both team's scores added together, so it is 84+117=201 points\n",
            "The answer is 201\n",
            "\n",
            "Question: Bella has two times as many marbles as frisbees. She also has 20 more frisbees than deck cards. If she buys 2/5 times more of each item, what would be the total number of the items she will have if she currently has 60 marbles?\n",
            "Let's think step by step\n",
            "When Bella buys 2/5 times more marbles, she'll have increased the number of marbles by 2/5*60 = 24\n",
            "The total number of marbles she'll have is 60+24 = 84\n",
            "If Bella currently has 60 marbles, and she has two times as many marbles as frisbees, she has 60/2 = 30 frisbees.\n",
            "If Bella buys 2/5 times more frisbees, she'll have 2/5*30 = 12 more frisbees.\n",
            "The total number of frisbees she'll have will increase to 30+12 = 42\n",
            "Bella also has 20 more frisbees than deck cards, meaning she has 30-20 = 10 deck cards\n",
            "If she buys 2/5 times more deck cards, she'll have 2/5*10 = 4 more deck cards.\n",
            "The total number of deck cards she'll have is 10+4 = 14\n",
            "Together, Bella will have a total of 14+42+84 = 140 items\n",
            "The answer is 140\n",
            "\n",
            "Question: A group of 4 fruit baskets contains 9 apples, 15 oranges, and 14 bananas in the first three baskets and 2 less of each fruit in the fourth basket. How many fruits are there?\n",
            "Let's think step by step\n",
            "For the first three baskets, the number of apples and oranges in one basket is 9+15=24\n",
            "In total, together with bananas, the number of fruits in one basket is 24+14=38 for the first three baskets.\n",
            "Since there are three baskets each having 38 fruits, there are 3*38=114 fruits in the first three baskets.\n",
            "The number of apples in the fourth basket is 9-2=7\n",
            "There are also 15-2=13 oranges in the fourth basket\n",
            "The combined number of oranges and apples in the fourth basket is 13+7=20\n",
            "The fourth basket also contains 14-2=12 bananas.\n",
            "In total, the fourth basket has 20+12=32 fruits.\n",
            "The four baskets together have 32+114=146 fruits.\n",
            "The answer is 146\n",
            "\n",
            "Question: You can buy 4 apples or 1 watermelon for the same price. You bought 36 fruits evenly split between oranges, apples and watermelons, and the price of 1 orange is $0.50. How much does 1 apple cost if your total bill was $66?\n",
            "Let's think step by step\n",
            "If 36 fruits were evenly split between 3 types of fruits, then I bought 36/3 = 12 units of each fruit\n",
            "If 1 orange costs $0.50 then 12 oranges will cost $0.50 * 12 = $6\n",
            "If my total bill was $66 and I spent $6 on oranges then I spent $66 - $6 = $60 on the other 2 fruit types.\n",
            "Assuming the price of watermelon is W, and knowing that you can buy 4 apples for the same price and that the price of one apple is A, then 1W=4A\n",
            "If we know we bought 12 watermelons and 12 apples for $60, then we know that $60 = 12W + 12A\n",
            "Knowing that 1W=4A, then we can convert the above to $60 = 12(4A) + 12A\n",
            "$60 = 48A + 12A\n",
            "$60 = 60A\n",
            "Then we know the price of one apple (A) is $60/60= $1\n",
            "The answer is 1\n",
            "\n",
            "Question: Susy goes to a large school with 800 students, while Sarah goes to a smaller school with only 300 students.  At the start of the school year, Susy had 100 social media followers.  She gained 40 new followers in the first week of the school year, half that in the second week, and half of that in the third week.  Sarah only had 50 social media followers at the start of the year, but she gained 90 new followers the first week, a third of that in the second week, and a third of that in the third week.  After three weeks, how many social media followers did the girl with the most total followers have?\n",
            "Let's think step by step\n",
            "After one week, Susy has 100+40 = 140 followers.\n",
            "In the second week, Susy gains 40/2 = 20 new followers.\n",
            "In the third week, Susy gains 20/2 = 10 new followers.\n",
            "In total, Susy finishes the three weeks with 140+20+10 = 170 total followers.\n",
            "After one week, Sarah has 50+90 = 140 followers.\n",
            "After the second week, Sarah gains 90/3 = 30 followers.\n",
            "After the third week, Sarah gains 30/3 = 10 followers.\n",
            "So, Sarah finishes the three weeks with 140+30+10 = 180 total followers.\n",
            "Thus, Sarah is the girl with the most total followers with a total of 180.\n",
            "The answer is 180\n",
            "\n",
            "Question: Sam bought a dozen boxes, each with 30 highlighter pens inside, for $10 each box. He rearranged five of these boxes into packages of six highlighters each and sold them for $3 per package. He sold the rest of the highlighters separately at the rate of three pens for $2. How much profit did he make in total, in dollars?\n",
            "Let's think step by step\n",
            "Sam bought 12 boxes x $10 = $120 worth of highlighters.\n",
            "He bought 12 * 30 = 360 highlighters in total.\n",
            "Sam then took 5 boxes × 6 highlighters/box = 30 highlighters.\n",
            "He sold these boxes for 5 * $3 = $15\n",
            "After selling these 5 boxes there were 360 - 30 = 330 highlighters remaining.\n",
            "These form 330 / 3 = 110 groups of three pens.\n",
            "He sold each of these groups for $2 each, so made 110 * 2 = $220 from them.\n",
            "In total, then, he earned $220 + $15 = $235.\n",
            "Since his original cost was $120, he earned $235 - $120 = $115 in profit.\n",
            "The answer is 115\n",
            "\n",
            "Question: In a certain school, 2/3 of the male students like to play basketball, but only 1/5 of the female students like to play basketball. What percent of the population of the school do not like to play basketball if the ratio of the male to female students is 3:2 and there are 1000 students?\n",
            "Let's think step by step\n",
            "The students are divided into 3 + 2 = 5 parts where 3 parts are for males and 2 parts are for females.\n",
            "Each part represents 1000/5 = 200 students.\n",
            "So, there are 3 x 200 = 600 males.\n",
            "And there are 2 x 200 = 400 females.\n",
            "Hence, 600 x 2/3 = 400 males play basketball.\n",
            "And 400 x 1/5 = 80 females play basketball.\n",
            "A total of 400 + 80 = 480 students play basketball.\n",
            "Therefore, 1000 - 480 = 520 do not like to play basketball.\n",
            "The percentage of the school that do not like to play basketball is 520/1000 * 100 = 52\n",
            "The answer is 52\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prompt_complex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e1e5d04e-ce12-4407-a150-4692c20ff4b0",
      "metadata": {
        "tags": [],
        "id": "e1e5d04e-ce12-4407-a150-4692c20ff4b0"
      },
      "outputs": [],
      "source": [
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_chain,\n",
        "    wait_fixed\n",
        ")\n",
        "\n",
        "@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +\n",
        "                       [wait_fixed(5) for i in range(2)] +\n",
        "                       [wait_fixed(10)]))\n",
        "def completion_with_backoff(**kwargs):\n",
        "    return openai.chat.completions.create(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1204557b-25f8-458c-a95b-3e2db046595c",
      "metadata": {
        "tags": [],
        "id": "1204557b-25f8-458c-a95b-3e2db046595c"
      },
      "outputs": [],
      "source": [
        "def test_answer(pred_str, ans_str):\n",
        "    pattern = '\\d*\\.?\\d+'\n",
        "    pred = re.findall(pattern, pred_str)\n",
        "    if(len(pred) >= 1):\n",
        "        # print(pred_str)\n",
        "        pred = pred[-1]\n",
        "        gold = re.findall(pattern, ans_str)\n",
        "        # print(ans_str)\n",
        "        gold = gold[-1]\n",
        "        return pred == gold\n",
        "    else: return False\n",
        "\n",
        "def parse_pred_ans(filename):\n",
        "    with open(filename) as fd: lines = fd.readlines()\n",
        "    am, a = None, None\n",
        "    num_q, acc = 0, 0\n",
        "    current_mode = 'none'\n",
        "    questions = []\n",
        "    ans_pred = []\n",
        "    ans_gold = []\n",
        "    for l in lines:\n",
        "        if(l.startswith('Q: ')):\n",
        "            if(am is not None and a is not None):\n",
        "                questions.append(q)\n",
        "                ans_pred.append(am)\n",
        "                ans_gold.append(a)\n",
        "                if(test_answer(am, a)):\n",
        "                    acc += 1\n",
        "            current_mode = 'q'\n",
        "            q = l\n",
        "            num_q += 1\n",
        "        elif(l.startswith('A_model:')):\n",
        "            current_mode = 'am'\n",
        "            am = l\n",
        "        elif(l.startswith('A:')):\n",
        "            current_mode = 'a'\n",
        "            a = l\n",
        "        else:\n",
        "            if(current_mode == 'q'): q += l\n",
        "            elif(current_mode == 'am'): am += l\n",
        "            elif(current_mode == 'a'): a += l\n",
        "            else:\n",
        "                raise ValueError(current_mode)\n",
        "\n",
        "    questions.append(q)\n",
        "    ans_pred.append(am)\n",
        "    ans_gold.append(a)\n",
        "    if(test_answer(am, a)):\n",
        "        acc += 1\n",
        "    print('num_q %d correct %d ratio %.4f' % (num_q, acc, float(acc / num_q)))\n",
        "    return questions, ans_pred, ans_gold\n",
        "\n",
        "def test_finished(ans_model):\n",
        "    if('answer is' in ans_model): return True\n",
        "    else: return False\n",
        "\n",
        "def extract_ans(ans_model):\n",
        "    ans_model = ans_model.split('\\n')\n",
        "    ans = []\n",
        "    residual = []\n",
        "    for li, al in enumerate(ans_model):\n",
        "        ans.append(al)\n",
        "        if('answer is' in al):\n",
        "            break\n",
        "    residual = list(ans_model[li + 1:])\n",
        "    ans = '\\n'.join(ans)\n",
        "    residual = '\\n'.join(residual)\n",
        "    return ans, residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "44e7f8ce-f9e7-4c04-96fa-066c023ba4cc",
      "metadata": {
        "tags": [],
        "id": "44e7f8ce-f9e7-4c04-96fa-066c023ba4cc"
      },
      "outputs": [],
      "source": [
        "prompt_q = prompt_complex + '\\nQuestion: ' + gsm8k_test[1]['question'] + '\\n'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "54e82439-47e4-4e72-ad44-e479c9db3b1b",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54e82439-47e4-4e72-ad44-e479c9db3b1b",
        "outputId": "4ca79cde-7e6f-49f9-8d35-23fdad5bb68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Angelo and Melanie want to plan how many hours over the next week they should study together for their test next week. They have 2 chapters of their textbook to study and 4 worksheets to memorize. They figure out that they should dedicate 3 hours to each chapter of their textbook and 1.5 hours for each worksheet. If they plan to study no more than 4 hours each day, how many days should they plan to study total over the next week if they take a 10-minute break every hour, include 3 10-minute snack breaks each day, and 30 minutes for lunch each day?\n",
            "Let's think step by step\n",
            "Angelo and Melanie think they should dedicate 3 hours to each of the 2 chapters, 3 hours x 2 chapters = 6 hours total.\n",
            "For the worksheets they plan to dedicate 1.5 hours for each worksheet, 1.5 hours x 4 worksheets = 6 hours total.\n",
            "Angelo and Melanie need to start with planning 12 hours to study, at 4 hours a day, 12 / 4 = 3 days.\n",
            "However, they need to include time for breaks and lunch. Every hour they want to include a 10-minute break, so 12 total hours x 10 minutes = 120 extra minutes for breaks.\n",
            "They also want to include 3 10-minute snack breaks, 3 x 10 minutes = 30 minutes.\n",
            "And they want to include 30 minutes for lunch each day, so 120 minutes for breaks + 30 minutes for snack breaks + 30 minutes for lunch = 180 minutes, or 180 / 60 minutes per hour = 3 extra hours.\n",
            "So Angelo and Melanie want to plan 12 hours to study + 3 hours of breaks = 15 hours total.\n",
            "They want to study no more than 4 hours each day, 15 hours / 4 hours each day = 3.75\n",
            "They will need to plan to study 4 days to allow for all the time they need.\n",
            "The answer is 4\n",
            "\n",
            "Question: Mark's basketball team scores 25 2 pointers, 8 3 pointers and 10 free throws.  Their opponents score double the 2 pointers but half the 3 pointers and free throws.  What's the total number of points scored by both teams added together?\n",
            "Let's think step by step\n",
            "Mark's team scores 25 2 pointers, meaning they scored 25*2= 50 points in 2 pointers.\n",
            "His team also scores 6 3 pointers, meaning they scored 8*3= 24 points in 3 pointers\n",
            "They scored 10 free throws, and free throws count as one point so they scored 10*1=10 points in free throws.\n",
            "All together his team scored 50+24+10= 84 points\n",
            "Mark's opponents scored double his team's number of 2 pointers, meaning they scored 50*2=100 points in 2 pointers.\n",
            "His opponents scored half his team's number of 3 pointers, meaning they scored 24/2= 12 points in 3 pointers.\n",
            "They also scored half Mark's team's points in free throws, meaning they scored 10/2=5 points in free throws.\n",
            "All together Mark's opponents scored 100+12+5=117 points\n",
            "The total score for the game is both team's scores added together, so it is 84+117=201 points\n",
            "The answer is 201\n",
            "\n",
            "Question: Bella has two times as many marbles as frisbees. She also has 20 more frisbees than deck cards. If she buys 2/5 times more of each item, what would be the total number of the items she will have if she currently has 60 marbles?\n",
            "Let's think step by step\n",
            "When Bella buys 2/5 times more marbles, she'll have increased the number of marbles by 2/5*60 = 24\n",
            "The total number of marbles she'll have is 60+24 = 84\n",
            "If Bella currently has 60 marbles, and she has two times as many marbles as frisbees, she has 60/2 = 30 frisbees.\n",
            "If Bella buys 2/5 times more frisbees, she'll have 2/5*30 = 12 more frisbees.\n",
            "The total number of frisbees she'll have will increase to 30+12 = 42\n",
            "Bella also has 20 more frisbees than deck cards, meaning she has 30-20 = 10 deck cards\n",
            "If she buys 2/5 times more deck cards, she'll have 2/5*10 = 4 more deck cards.\n",
            "The total number of deck cards she'll have is 10+4 = 14\n",
            "Together, Bella will have a total of 14+42+84 = 140 items\n",
            "The answer is 140\n",
            "\n",
            "Question: A group of 4 fruit baskets contains 9 apples, 15 oranges, and 14 bananas in the first three baskets and 2 less of each fruit in the fourth basket. How many fruits are there?\n",
            "Let's think step by step\n",
            "For the first three baskets, the number of apples and oranges in one basket is 9+15=24\n",
            "In total, together with bananas, the number of fruits in one basket is 24+14=38 for the first three baskets.\n",
            "Since there are three baskets each having 38 fruits, there are 3*38=114 fruits in the first three baskets.\n",
            "The number of apples in the fourth basket is 9-2=7\n",
            "There are also 15-2=13 oranges in the fourth basket\n",
            "The combined number of oranges and apples in the fourth basket is 13+7=20\n",
            "The fourth basket also contains 14-2=12 bananas.\n",
            "In total, the fourth basket has 20+12=32 fruits.\n",
            "The four baskets together have 32+114=146 fruits.\n",
            "The answer is 146\n",
            "\n",
            "Question: You can buy 4 apples or 1 watermelon for the same price. You bought 36 fruits evenly split between oranges, apples and watermelons, and the price of 1 orange is $0.50. How much does 1 apple cost if your total bill was $66?\n",
            "Let's think step by step\n",
            "If 36 fruits were evenly split between 3 types of fruits, then I bought 36/3 = 12 units of each fruit\n",
            "If 1 orange costs $0.50 then 12 oranges will cost $0.50 * 12 = $6\n",
            "If my total bill was $66 and I spent $6 on oranges then I spent $66 - $6 = $60 on the other 2 fruit types.\n",
            "Assuming the price of watermelon is W, and knowing that you can buy 4 apples for the same price and that the price of one apple is A, then 1W=4A\n",
            "If we know we bought 12 watermelons and 12 apples for $60, then we know that $60 = 12W + 12A\n",
            "Knowing that 1W=4A, then we can convert the above to $60 = 12(4A) + 12A\n",
            "$60 = 48A + 12A\n",
            "$60 = 60A\n",
            "Then we know the price of one apple (A) is $60/60= $1\n",
            "The answer is 1\n",
            "\n",
            "Question: Susy goes to a large school with 800 students, while Sarah goes to a smaller school with only 300 students.  At the start of the school year, Susy had 100 social media followers.  She gained 40 new followers in the first week of the school year, half that in the second week, and half of that in the third week.  Sarah only had 50 social media followers at the start of the year, but she gained 90 new followers the first week, a third of that in the second week, and a third of that in the third week.  After three weeks, how many social media followers did the girl with the most total followers have?\n",
            "Let's think step by step\n",
            "After one week, Susy has 100+40 = 140 followers.\n",
            "In the second week, Susy gains 40/2 = 20 new followers.\n",
            "In the third week, Susy gains 20/2 = 10 new followers.\n",
            "In total, Susy finishes the three weeks with 140+20+10 = 170 total followers.\n",
            "After one week, Sarah has 50+90 = 140 followers.\n",
            "After the second week, Sarah gains 90/3 = 30 followers.\n",
            "After the third week, Sarah gains 30/3 = 10 followers.\n",
            "So, Sarah finishes the three weeks with 140+30+10 = 180 total followers.\n",
            "Thus, Sarah is the girl with the most total followers with a total of 180.\n",
            "The answer is 180\n",
            "\n",
            "Question: Sam bought a dozen boxes, each with 30 highlighter pens inside, for $10 each box. He rearranged five of these boxes into packages of six highlighters each and sold them for $3 per package. He sold the rest of the highlighters separately at the rate of three pens for $2. How much profit did he make in total, in dollars?\n",
            "Let's think step by step\n",
            "Sam bought 12 boxes x $10 = $120 worth of highlighters.\n",
            "He bought 12 * 30 = 360 highlighters in total.\n",
            "Sam then took 5 boxes × 6 highlighters/box = 30 highlighters.\n",
            "He sold these boxes for 5 * $3 = $15\n",
            "After selling these 5 boxes there were 360 - 30 = 330 highlighters remaining.\n",
            "These form 330 / 3 = 110 groups of three pens.\n",
            "He sold each of these groups for $2 each, so made 110 * 2 = $220 from them.\n",
            "In total, then, he earned $220 + $15 = $235.\n",
            "Since his original cost was $120, he earned $235 - $120 = $115 in profit.\n",
            "The answer is 115\n",
            "\n",
            "Question: In a certain school, 2/3 of the male students like to play basketball, but only 1/5 of the female students like to play basketball. What percent of the population of the school do not like to play basketball if the ratio of the male to female students is 3:2 and there are 1000 students?\n",
            "Let's think step by step\n",
            "The students are divided into 3 + 2 = 5 parts where 3 parts are for males and 2 parts are for females.\n",
            "Each part represents 1000/5 = 200 students.\n",
            "So, there are 3 x 200 = 600 males.\n",
            "And there are 2 x 200 = 400 females.\n",
            "Hence, 600 x 2/3 = 400 males play basketball.\n",
            "And 400 x 1/5 = 80 females play basketball.\n",
            "A total of 400 + 80 = 480 students play basketball.\n",
            "Therefore, 1000 - 480 = 520 do not like to play basketball.\n",
            "The percentage of the school that do not like to play basketball is 520/1000 * 100 = 52\n",
            "The answer is 52\n",
            "\n",
            "Question: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prompt_q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d6597b15-0a08-4ff7-b8b1-ba090cd91e16",
      "metadata": {
        "tags": [],
        "id": "d6597b15-0a08-4ff7-b8b1-ba090cd91e16"
      },
      "outputs": [],
      "source": [
        "response = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_q},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "46225b43-db46-4cd6-8ac6-98c41a2f0506",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "46225b43-db46-4cd6-8ac6-98c41a2f0506",
        "outputId": "3541d8fe-75ab-4e4b-a4dc-3b6b87a203cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Let's think step by step:\\nIf a robe takes 2 bolts of blue fiber, then it requires 2/2 = 1 bolt of white fiber.\\nSo, in total, the robe takes 2 (blue) + 1 (white) = 3 bolts.\\nThe answer is 3.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "14ca497f-efaa-4410-afaf-4f70e1e37605",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14ca497f-efaa-4410-afaf-4f70e1e37605",
        "outputId": "582ca326-86a0-42f0-9345-4257151d747b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's think step by step:\n",
            "If a robe takes 2 bolts of blue fiber, then it requires 2/2 = 1 bolt of white fiber.\n",
            "So, in total, the robe takes 2 (blue) + 1 (white) = 3 bolts.\n",
            "The answer is 3.\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 에서 쓰인 CoT prompt 를 LLMlinguage2 를 사용하여 300 token target 으로 compress 후 compress 하지 않은 경우와 결과 비교\n"
      ],
      "metadata": {
        "id": "P1q3JfO1ZVrN"
      },
      "id": "P1q3JfO1ZVrN"
    },
    {
      "cell_type": "code",
      "source": [
        "from llmlingua import PromptCompressor"
      ],
      "metadata": {
        "id": "xUhoI0PLZUxK"
      },
      "id": "xUhoI0PLZUxK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_lingua = PromptCompressor(device_map=\"cpu\")"
      ],
      "metadata": {
        "id": "vtN3GUj5ZVDW"
      },
      "id": "vtN3GUj5ZVDW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_prompt = llm_lingua.compress_prompt(prompt_q, instruction=\"\", question=\"\", target_token=200)"
      ],
      "metadata": {
        "id": "iSAe9jjeZVHp"
      },
      "id": "iSAe9jjeZVHp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "zI-pxss_Zi8P",
        "outputId": "639393d5-80aa-4812-b9b1-53a77798ff48"
      },
      "id": "zI-pxss_Zi8P",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'compressed_prompt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3c212a7cbb09>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompressed_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'compressed_prompt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb3e426-9907-4d73-81d5-3ba0898380ef",
      "metadata": {
        "id": "bfb3e426-9907-4d73-81d5-3ba0898380ef"
      },
      "source": [
        "# Complex Prompt Random Sampling, Acc 77.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls \"./drive/MyDrive/Colab Notebooks/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGrC03s8TmF9",
        "outputId": "c31394eb-7b2d-4974-f0b5-94ff6a0932fb"
      },
      "id": "GGrC03s8TmF9",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1_gpt3.5turbo_gsm8k_complex.ipynb\tprompt_engineering.ipynb  Untitled0.ipynb\n",
            "gpt3.5turbo_gsm8k_complex_202406.ipynb\tprompt_hardest.txt\t  validation_index.npy\n",
            "outputs\t\t\t\t\tUntitled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "329eaf72-c549-453d-9a4c-7e1ab32400c2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "329eaf72-c549-453d-9a4c-7e1ab32400c2",
        "outputId": "f5b9d1fa-bd8a-49e4-9662-773d6cdfe602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1319/1319 [1:06:20<00:00,  3.02s/it]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "with open('./drive/MyDrive/Colab Notebooks/outputs/test_gpt_3.5_turbo_complex.txt', 'w') as fd:\n",
        "    for q, a in tqdm(zip(gsm8k_test['question'], gsm8k_test['answer']),\n",
        "                               total=len(gsm8k_test['question'])):\n",
        "\n",
        "        prompt_q = prompt_complex + '\\nQuestion: ' + q + '\\n'\n",
        "\n",
        "        response = completion_with_backoff(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_q},\n",
        "                ]\n",
        "            )\n",
        "        ans_model = response.choices[0].message.content\n",
        "        ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "        fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "        i += 1\n",
        "        # if(i == 2): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "efef9d01-229f-4b68-8ff7-bb1d9fca80ba",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efef9d01-229f-4b68-8ff7-bb1d9fca80ba",
        "outputId": "0b457d23-3992-4666-e2e2-44ea44e826ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_q 1319 correct 937 ratio 0.7104\n"
          ]
        }
      ],
      "source": [
        "_, _, _ = parse_pred_ans('./drive/MyDrive/Colab Notebooks/outputs/test_gpt_3.5_turbo_complex.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae3f728-c9c0-483f-b89e-5a4080554d70",
      "metadata": {
        "id": "1ae3f728-c9c0-483f-b89e-5a4080554d70"
      },
      "source": [
        "# Complex Prompt Greedy Decoding, Acc 78.85"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "265654fb-e87f-479e-b20d-91913179d309",
      "metadata": {
        "tags": [],
        "id": "265654fb-e87f-479e-b20d-91913179d309",
        "outputId": "efb7abe1-0df3-44cb-8e24-7fd1aac1306c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [2:04:18<00:00,  5.65s/it]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "with open('outputs/test_gpt_3.5_turbo_complex_temp_0.txt', 'w') as fd:\n",
        "    for q, a in tqdm(zip(gsm8k_test['question'], gsm8k_test['answer']),\n",
        "                               total=len(gsm8k_test['question'])):\n",
        "\n",
        "        prompt_q = prompt_complex + '\\nQuestion: ' + q + '\\n'\n",
        "\n",
        "        response = completion_with_backoff(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_q},\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "        ans_model = response.choices[0].message.content\n",
        "        ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "        fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "        i += 1\n",
        "        # if(i == 2): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad45c72-2349-4be3-a76a-7f0f0f5d8e06",
      "metadata": {
        "tags": [],
        "id": "aad45c72-2349-4be3-a76a-7f0f0f5d8e06",
        "outputId": "535ee3f9-e1fc-4979-cb6c-48d0a94caeef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_q 1319 correct 1040 ratio 0.7885\n"
          ]
        }
      ],
      "source": [
        "_, _, _ = parse_pred_ans('outputs/test_gpt_3.5_turbo_complex_temp_0.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d6083d-7f10-4e1e-b947-565fa72e0bd0",
      "metadata": {
        "id": "a7d6083d-7f10-4e1e-b947-565fa72e0bd0"
      },
      "source": [
        "# Baseline Prompt Greedy Decoding, Acc 74.98"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "444db3b1-7352-4dc9-a717-dc808e3961ed",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "444db3b1-7352-4dc9-a717-dc808e3961ed",
        "outputId": "8b2c3531-3ae1-41cf-fc73-f5abff9a3686"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../gsm8k/lib_prompt/prompt_original.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-31eb9b344918>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprompt_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../gsm8k/lib_prompt/prompt_original.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../gsm8k/lib_prompt/prompt_original.txt'"
          ]
        }
      ],
      "source": [
        "prompt_original = open('../gsm8k/lib_prompt/prompt_original.txt').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ce8d3d-9b1f-41ca-bfbe-2197d4602526",
      "metadata": {
        "tags": [],
        "id": "d5ce8d3d-9b1f-41ca-bfbe-2197d4602526",
        "outputId": "43e35b92-2ec7-424f-8144-da1e947281d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [2:36:17<00:00,  7.11s/it]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "with open('outputs/test_gpt_3.5_turbo_original_temp_0.txt', 'w') as fd:\n",
        "    for q, a in tqdm(zip(gsm8k_test['question'], gsm8k_test['answer']),\n",
        "                               total=len(gsm8k_test['question'])):\n",
        "\n",
        "        prompt_q = prompt_original + '\\nQuestion: ' + q + '\\n'\n",
        "\n",
        "        response = completion_with_backoff(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_q},\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "        ans_model = response.choices[0].message.content\n",
        "        ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "        fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "        i += 1\n",
        "        # if(i == 2): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d695da9-7324-4d72-9d52-ace669da7443",
      "metadata": {
        "tags": [],
        "id": "3d695da9-7324-4d72-9d52-ace669da7443",
        "outputId": "d7023837-6826-4794-c0ac-489ce7436897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_q 1319 correct 989 ratio 0.7498\n"
          ]
        }
      ],
      "source": [
        "_, _, _ = parse_pred_ans('outputs/test_gpt_3.5_turbo_original_temp_0.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6951e74d-0b95-45bb-88e3-b34e3a4472d6",
      "metadata": {
        "id": "6951e74d-0b95-45bb-88e3-b34e3a4472d6"
      },
      "source": [
        "# Baseline Prompt, Dialog In-Context Learning, Acc 76.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b6a7cd-8e7c-4988-96b5-0afb759d3bcf",
      "metadata": {
        "tags": [],
        "id": "65b6a7cd-8e7c-4988-96b5-0afb759d3bcf"
      },
      "outputs": [],
      "source": [
        "def make_dialog_prompt(prompt):\n",
        "    messages = []\n",
        "    messages.append({\"role\": \"system\", \"content\": \"Follow the given examples and answer the question.\"})\n",
        "    cases = prompt.split(\"\\n\\n\")\n",
        "    for c in cases[:-1]:\n",
        "        question = c.split(\"\\n\")[:2]\n",
        "        messages.append({\"role\": \"user\", \"content\": \"\\n\".join(question)})\n",
        "        answer = c.split(\"\\n\")[2:]\n",
        "        messages.append({\"role\": \"assistant\", \"content\": \"\\n\".join(answer)})\n",
        "    messages.append({\"role\": \"user\", \"content\": cases[-1] + \"Let's think step by step\"})\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76b5c24-d6ea-4bdf-b9e8-956eb52eb559",
      "metadata": {
        "tags": [],
        "id": "a76b5c24-d6ea-4bdf-b9e8-956eb52eb559",
        "outputId": "86b1f71f-98a5-4b8a-83f0-a1b1371be874"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [2:57:13<00:00,  8.06s/it]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "with open('outputs/test_gpt_3.5_turbo_original_dialog_icl.txt', 'w') as fd:\n",
        "    for q, a in tqdm(zip(gsm8k_test['question'], gsm8k_test['answer']),\n",
        "                               total=len(gsm8k_test['question'])):\n",
        "\n",
        "        prompt_q = prompt_original + '\\nQuestion: ' + q + '\\n'\n",
        "        dialog_prompt = make_dialog_prompt(prompt_q)\n",
        "\n",
        "        response = completion_with_backoff(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=dialog_prompt,\n",
        "              temperature=0\n",
        "            )\n",
        "        ans_model = response.choices[0].message.content\n",
        "        ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "        fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "        i += 1\n",
        "        # if(i == 2): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec899995-c9f3-458a-a290-8433b882f21d",
      "metadata": {
        "tags": [],
        "id": "ec899995-c9f3-458a-a290-8433b882f21d",
        "outputId": "f3aebcb2-83e8-466f-d6de-c0e9d9db8868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_q 1319 correct 1013 ratio 0.7680\n"
          ]
        }
      ],
      "source": [
        "_, _, _ = parse_pred_ans('outputs/test_gpt_3.5_turbo_original_dialog_icl.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64368f0-ec02-49ef-bfe2-ad2357d578c4",
      "metadata": {
        "id": "c64368f0-ec02-49ef-bfe2-ad2357d578c4"
      },
      "source": [
        "# Complex Prompt, Dialog In-Context Learning, Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1bf1b1-f4c6-47e1-b876-168eec3c47d2",
      "metadata": {
        "tags": [],
        "id": "6f1bf1b1-f4c6-47e1-b876-168eec3c47d2",
        "outputId": "b3228fa4-b59d-4b64-8766-1dc227dd0284"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1319/1319 [2:43:01<00:00,  7.42s/it]\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "with open('outputs/test_gpt_3.5_turbo_complex_dialog_icl.txt', 'w') as fd:\n",
        "    for q, a in tqdm(zip(gsm8k_test['question'], gsm8k_test['answer']),\n",
        "                               total=len(gsm8k_test['question'])):\n",
        "\n",
        "        prompt_q = prompt_complex + '\\nQuestion: ' + q + '\\n'\n",
        "        dialog_prompt = make_dialog_prompt(prompt_q)\n",
        "\n",
        "        response = completion_with_backoff(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=dialog_prompt,\n",
        "              temperature=0\n",
        "            )\n",
        "        ans_model = response.choices[0].message.content\n",
        "        ans_, residual = extract_ans(ans_model)\n",
        "\n",
        "        fd.write('Q: %s\\nA_model:\\n%s\\nA:\\n%s\\n\\n' % (q, ans_, a))\n",
        "        i += 1\n",
        "        # if(i == 2): break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b7f396-a31d-4206-aefe-8d49b9130bdd",
      "metadata": {
        "tags": [],
        "id": "58b7f396-a31d-4206-aefe-8d49b9130bdd",
        "outputId": "04a65a6c-828d-4222-8df2-abfe13306762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_q 1319 correct 988 ratio 0.7491\n"
          ]
        }
      ],
      "source": [
        "_, _, _ = parse_pred_ans('outputs/test_gpt_3.5_turbo_complex_dialog_icl.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be091b7-083b-4ba9-a83d-c3628494c782",
      "metadata": {
        "id": "6be091b7-083b-4ba9-a83d-c3628494c782"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97cc178f7ca44b2195796bc379a08033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68e4ce4642694f8c85a958a5ae89ad34",
              "IPY_MODEL_8b9e51916f7048ed950b7dc4c37b5115",
              "IPY_MODEL_2f468f8cd0fe46088cc802873af766ac"
            ],
            "layout": "IPY_MODEL_66c27484052f4e85887da3fbb5062774"
          }
        },
        "68e4ce4642694f8c85a958a5ae89ad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7333f38ee544fbaa861d906a4b4c5d2",
            "placeholder": "​",
            "style": "IPY_MODEL_86be23882fcf4fa491ac8f83fc48f304",
            "value": "Downloading readme: 100%"
          }
        },
        "8b9e51916f7048ed950b7dc4c37b5115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83bb9fea84d249f39aae95d81ec212fd",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c353342ed424a19bcc008d52d55c349",
            "value": 7940
          }
        },
        "2f468f8cd0fe46088cc802873af766ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6888e5381b47989992048f63ce0dec",
            "placeholder": "​",
            "style": "IPY_MODEL_84574b7e42f6456fa215d07712a26776",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 420kB/s]"
          }
        },
        "66c27484052f4e85887da3fbb5062774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7333f38ee544fbaa861d906a4b4c5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86be23882fcf4fa491ac8f83fc48f304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83bb9fea84d249f39aae95d81ec212fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c353342ed424a19bcc008d52d55c349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd6888e5381b47989992048f63ce0dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84574b7e42f6456fa215d07712a26776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee56da57a9f4956aa31c11c385b98d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82bca68527274246a2459033e4ba3312",
              "IPY_MODEL_e5141d90c54740eca2ca3e30952ab757",
              "IPY_MODEL_f5ae5f4701e94b5d9ba1c8ed18b56b75"
            ],
            "layout": "IPY_MODEL_25c6b14e24c54cadad2f5dbc559c1b64"
          }
        },
        "82bca68527274246a2459033e4ba3312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2847074f8b0d443482592ac26653f15f",
            "placeholder": "​",
            "style": "IPY_MODEL_5704a94b68c84cb4a34ec62f6ba42def",
            "value": "Downloading data: 100%"
          }
        },
        "e5141d90c54740eca2ca3e30952ab757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18434b8788c04a33b2814bd5310d1e70",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1ce85068de64d018982e1d43490160c",
            "value": 2306545
          }
        },
        "f5ae5f4701e94b5d9ba1c8ed18b56b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331e35f0c96e4fa3af53db1fd4a49dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_9a3e7cb1b93343ab97fcbc167ace157d",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 8.03MB/s]"
          }
        },
        "25c6b14e24c54cadad2f5dbc559c1b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2847074f8b0d443482592ac26653f15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5704a94b68c84cb4a34ec62f6ba42def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18434b8788c04a33b2814bd5310d1e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ce85068de64d018982e1d43490160c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "331e35f0c96e4fa3af53db1fd4a49dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3e7cb1b93343ab97fcbc167ace157d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a45d4538b60041b88103878dae8b70e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a123ef0a6ea84ac5975c133b8ae42377",
              "IPY_MODEL_63f66c4d589b44db8251eb6d0c6b1e5c",
              "IPY_MODEL_044893f98f274b3ea56c619a6f28c10d"
            ],
            "layout": "IPY_MODEL_00dc570a45e142fcadee3c428ee85026"
          }
        },
        "a123ef0a6ea84ac5975c133b8ae42377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f8df9d64b53477e90f52e024b3f72e1",
            "placeholder": "​",
            "style": "IPY_MODEL_5626d4f305b443d4973d846e418c5fc3",
            "value": "Downloading data: 100%"
          }
        },
        "63f66c4d589b44db8251eb6d0c6b1e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e713b1d26d494d2698d26a81aa2eb7e5",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a542f3b083c479f8190e14bf0213a02",
            "value": 419088
          }
        },
        "044893f98f274b3ea56c619a6f28c10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0f70d02eac4afca8ce176c8b289f38",
            "placeholder": "​",
            "style": "IPY_MODEL_6c5b106324d541d2abbe5ea7b6075799",
            "value": " 419k/419k [00:00&lt;00:00, 2.34MB/s]"
          }
        },
        "00dc570a45e142fcadee3c428ee85026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8df9d64b53477e90f52e024b3f72e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5626d4f305b443d4973d846e418c5fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e713b1d26d494d2698d26a81aa2eb7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a542f3b083c479f8190e14bf0213a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df0f70d02eac4afca8ce176c8b289f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5b106324d541d2abbe5ea7b6075799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22cce448cfdc4d7bb14be3e354475f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be5af9a8cd094004baf7eea377026b2e",
              "IPY_MODEL_ea3109c1c4e644cfa5e8c37e37079ee1",
              "IPY_MODEL_eaa79aa6911840948c3139e52ccbf726"
            ],
            "layout": "IPY_MODEL_1ad278354cbb469e9854325d6474c18d"
          }
        },
        "be5af9a8cd094004baf7eea377026b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_198d121c4619427bb6a88a2417e7facf",
            "placeholder": "​",
            "style": "IPY_MODEL_f2047c61e68e4e0d83130c85132199c8",
            "value": "Generating train split: 100%"
          }
        },
        "ea3109c1c4e644cfa5e8c37e37079ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff3b6c2f5134b97b2e8fb09880d8dd7",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_854add91e47040e68e795693d276b3cf",
            "value": 7473
          }
        },
        "eaa79aa6911840948c3139e52ccbf726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af15ebcd1c84f058d15ece69058286b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2d0e270e544412a9081f94f2e39dd5",
            "value": " 7473/7473 [00:00&lt;00:00, 88873.86 examples/s]"
          }
        },
        "1ad278354cbb469e9854325d6474c18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198d121c4619427bb6a88a2417e7facf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2047c61e68e4e0d83130c85132199c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff3b6c2f5134b97b2e8fb09880d8dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854add91e47040e68e795693d276b3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af15ebcd1c84f058d15ece69058286b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2d0e270e544412a9081f94f2e39dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68708518c604d0c9e43f81bd5dd1541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e1c5dc51e3f4fd1a61e474513b6eade",
              "IPY_MODEL_b20c9f280562496f8340db541742ea5f",
              "IPY_MODEL_3087b995afaf479895acc1894aee6c96"
            ],
            "layout": "IPY_MODEL_4087824cb5594a8b840946ffab72a7d4"
          }
        },
        "7e1c5dc51e3f4fd1a61e474513b6eade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d11d44196342d1bd9f9a0735b20c77",
            "placeholder": "​",
            "style": "IPY_MODEL_6b13863bb3d643fc91172fc263881c35",
            "value": "Generating test split: 100%"
          }
        },
        "b20c9f280562496f8340db541742ea5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7deac8a75f44fb5991d985d8d281d2c",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a23f6dc085740c2bd3b9268857a6efe",
            "value": 1319
          }
        },
        "3087b995afaf479895acc1894aee6c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d1126c608342e69b440a3975dfb616",
            "placeholder": "​",
            "style": "IPY_MODEL_2cfa4e684ae34a90b9d4316ece13a5eb",
            "value": " 1319/1319 [00:00&lt;00:00, 41402.21 examples/s]"
          }
        },
        "4087824cb5594a8b840946ffab72a7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d11d44196342d1bd9f9a0735b20c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b13863bb3d643fc91172fc263881c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7deac8a75f44fb5991d985d8d281d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a23f6dc085740c2bd3b9268857a6efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3d1126c608342e69b440a3975dfb616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cfa4e684ae34a90b9d4316ece13a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}